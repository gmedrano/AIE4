The paper "Extending Llama-3’s Context Ten-Fold Overnight" extensively evaluates the Llama-3-8B-Instruct model, which has been enhanced to handle much longer contexts, increasing the context length from 8K to 80K through QLoRA fine-tuning. This adjustment significantly boosts the model's performance across several evaluation tasks. Here's a brief overview of the tasks where the extended model was assessed:

1. **NIHS**: This evaluation task is mentioned in the context of demonstrating the model's capabilities, although specific details about this task are not deeply discussed in the available summaries.
2. **Topic Retrieval**: This task assesses the model's ability to retrieve relevant information based on the topic, showcasing its enhanced handling of extended contexts.
3. **Long-context Language Understanding**: Evaluates the model’s comprehension and interpretation skills in dealing with long text inputs.
4. **LongBench Tasks**: These encompass various real-world tasks that involve long-context scenarios, testing the model's practical applications in handling extended information.
5. **English Long-Book QA**: Focuses on question answering tasks based on long-form content in English, such as entire books, to test deep understanding and retrieval capabilities.
6. **Long-Book Summarization Tasks from InfiniteBench**: Challenges the model to summarize lengthy texts, which demonstrates its ability to condense and interpret extensive information efficiently.

These evaluations clearly demonstrate the model's advanced capabilities in processing significantly larger context sizes, maintaining high performance in understanding and generating responses based on extended texts.